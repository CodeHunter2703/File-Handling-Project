{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Sales Data Management System\n",
    "\n",
    "**Assignment Submission**  \n",
    "Author: Shivam Chaudhari \n",
    "Date: July 18, 2025\n",
    "\n",
    "\n",
    "A Python project to manage, update, and maintain product sales and metadata using CSV, JSON, and TXT files, organized with a robust folder structure. Built to meet coursework requirements for file handling and product management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS & SETUP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,json,csv\n",
    "#   ONLY FOR CHECKING THE CD\n",
    "# print(\"Current working directory:\", os.getcwd())\n",
    "# print(\"Files in directory:\", os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \n",
    "    product_details={}\n",
    "    product_descriptions={}\n",
    "    path_cw=os.getcwd()  # Shows current working directory\n",
    "    \n",
    "    # Accesing csv file data since its in main folder not inside any sub-folder hence no need to specify the path\n",
    "    with open('sales_data.csv',\"r\") as handle_sales:\n",
    "        reader=csv.reader(handle_sales)\n",
    "        next(reader)  # Skip the header row\n",
    "        sales_data = { row[0]: row[1:] for row in reader }\n",
    "    \n",
    "    \n",
    "    #Accsesing the .json file from folder --> product_details\n",
    "    product_details_json_files=os.listdir('product_details')\n",
    "    for json_file_name in product_details_json_files:\n",
    "        #since only using file name will give fof erorr then we need to give abs or relative path\n",
    "        file_path = os.path.join(path_cw,'product_details',json_file_name )\n",
    "        \n",
    "        # Ensure it's a file before opening (not a folder)\n",
    "        if os.path.isfile(file_path) and json_file_name.endswith('.json'):\n",
    "            \n",
    "            #since file names are seperated like details_{sku_id}.json that's why i used split on '_' and slicing to remove '.json'\n",
    "            prod_sku=json_file_name.split(\"_\")[1][:-5]      \n",
    "            \n",
    "            with open(file_path, 'r') as prod_details:\n",
    "                data = json.load(prod_details)  # use json.load() for file object\n",
    "                product_details[prod_sku]=data\n",
    "           \n",
    "   \n",
    "    #Accsesing the .txt file from folder --> product_descriptions\n",
    "    product_descriptions_txt_files=os.listdir('product_descriptions')\n",
    "    for txt_file_name in product_descriptions_txt_files:\n",
    "        #Building path \n",
    "        file_path = os.path.join(path_cw,'product_descriptions',txt_file_name )\n",
    "        #For file exist or not \n",
    "        if os.path.isfile(file_path) and txt_file_name.endswith('.txt'):\n",
    "            with open(file_path, 'r') as prod_desc:\n",
    "                prod_sku=txt_file_name.split(\"_\")[1][:-4]\n",
    "                descriptions=prod_desc.read()   #read the txt file using read which gives output in string datatype\n",
    "                product_descriptions[prod_sku]=descriptions\n",
    "      \n",
    "    return sales_data, product_details, product_descriptions\n",
    "\n",
    "sales_data, product_details, product_descriptions = load_data()\n",
    "# print(sales_data, product_details, product_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPDATE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for updating dictionary sales_data using update function\n",
    "def update_sales_data(to_update_prod,sales_data):\n",
    "    sales_data.update(to_update_prod)\n",
    "    return sales_data\n",
    "\n",
    "# for updating dictionary product_details using update function\n",
    "def update_product_details(to_update_prod,product_details):\n",
    "    product_details.update(to_update_prod)\n",
    "    return product_details\n",
    "\n",
    "# for updating dictionary product_descriptions using update function\n",
    "def update_product_description(to_update_prod,product_descriptions):\n",
    "    product_descriptions.update(to_update_prod)\n",
    "    return product_descriptions\n",
    "\n",
    "# instead of repeting i just made a function for error message\n",
    "def print_error(message):\n",
    "    border = \"#\" * 100\n",
    "    error_line = f\" ERROR: {message.upper()}! \"\n",
    "    print(f\"\\n{border}\\n{error_line.center(100, '#')}\\n{border}\\n\")\n",
    "\n",
    "\n",
    "def update( sales_data , product_details , product_descriptions):\n",
    "    #   FOR UPDATING SALES DATA\n",
    "    \n",
    "    # taking input for SKU id\n",
    "    prod_SKU=input(\"Enter Product SKU ID: \").strip()# using strip() to remove spaces from both sides to not cause any error\n",
    "\n",
    "    # validating the id\n",
    "    if len(prod_SKU)==13:\n",
    "        sales=input(\"Enter the sales past 14 days sepreted by spaces\").strip()\n",
    "        \n",
    "        # converting in int and also checking if they are whole number and not any charachter\n",
    "        #i could used to validate directly through the for loop but then i would need to again transverse through to see all sales are whole numbers.\n",
    "        sales=[int(day) for day in sales.split() if day.isdecimal() if int(day.strip()) >=0 ]\n",
    "        if len(sales)!=14:\n",
    "           print_error(\"INVALID DATA\")\n",
    "           return sales_data , product_details , product_descriptions\n",
    "    else:\n",
    "        print_error(\"INVALID SKU ID\")\n",
    "        return sales_data , product_details , product_descriptions #returning original dictionaries\n",
    "    # Function calling for adding in parent dictionary\n",
    "    result_sales = update_sales_data({prod_SKU: sales}, sales_data)\n",
    "    \n",
    "    #   FOR UPDATING SALES DETAILS\n",
    "    details={}\n",
    "    keys_details=['name', 'brand' , 'model' , 'specifications' , 'price' ,'availability' ]\n",
    "    for w in keys_details:\n",
    "        details[w]=input(f\"{prod_SKU} {w}: \")\n",
    "    \n",
    "    # Function calling for adding in parent dictionary\n",
    "    result_details = update_product_details({prod_SKU: details}, product_details)\n",
    "    \n",
    "    # FOR UPDATING DECRIPTION\n",
    "    description=input(f\"{prod_SKU} description: \")\n",
    "    if not description:\n",
    "        print_error(\"NO DESCRIPTION GIVEN\")\n",
    "        return sales_data , product_details , product_descriptions\n",
    "    \n",
    "    # Function calling for adding in parent dictionary\n",
    "    result_desc = update_product_description({prod_SKU: description}, product_descriptions)\n",
    "    \n",
    "    # succes message\n",
    "    print(f\"SUCCESFULLY UPDATED DATA FOR PRODUCT {prod_SKU}\".center(100, '#'))\n",
    "    # returning in a tuple output\n",
    " \n",
    "    return result_sales, result_details, result_desc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN UPDATE() â€“ optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  NOTE FOR UPDATING USE THE CALL BELOW u can uncomment it \n",
    "# sales_data , product_details , product_descriptions= update(sales_data , product_details , product_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5808240e-c1c3-4b5a-809d-7d433e8554a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to upate the mainfolder\n",
    "def dump_data(sales_data, product_details, product_descriptions, main_folder):\n",
    "    \"\"\"\n",
    "    Save all data dictionaries to disk, recreating folder structure as needed:\n",
    "      - sales_data.csv in main_folder\n",
    "      - product_details JSON files in main_folder/product_details\n",
    "      - product_descriptions TXT files in main_folder/product_descriptions\n",
    "    \"\"\"\n",
    "    # Checking main folder exists\n",
    "    os.makedirs(main_folder, exist_ok=True)\n",
    "    \n",
    "    # Dump sales_data into a CSV file in main_folder\n",
    "    sales_file_path = os.path.join(main_folder, \"sales_data.csv\")\n",
    "    with open(sales_file_path, 'w',newline='') as csvfile:\n",
    "        header = ['Product_SKU'] + [f'Day{i+1}' for i in range(14)]#first heading\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        for sku, sales_list in sales_data.items():\n",
    "            writer.writerow([sku]+sales_list)\n",
    "    \n",
    "    # Dump product_details as .json files in product_details subfolder by first making path for folder \"product_details\" and individual .json files\n",
    "    details_folder = os.path.join(main_folder, \"product_details\")\n",
    "    os.makedirs(details_folder, exist_ok=True)\n",
    "    for sku, details in product_details.items():\n",
    "        filename = f\"details_{sku}.json\"# since filname structure were like that no need use listdir()\n",
    "        filepath = os.path.join(details_folder, filename)\n",
    "        with open(filepath, 'w') as jsonfile:\n",
    "            json.dump(details, jsonfile)\n",
    "    \n",
    "    # Dump product_descriptions as .txt files in product_descriptions subfolder by first making path for folder \"product_descriptions\" and individual .txt files\n",
    "    descriptions_folder = os.path.join(main_folder, \"product_descriptions\")\n",
    "    os.makedirs(descriptions_folder, exist_ok=True)\n",
    "    for sku, description in product_descriptions.items():\n",
    "        filename = f\"details_{sku}.txt\"\n",
    "        filepath = os.path.join(descriptions_folder, filename)\n",
    "        with open(filepath, 'w') as txtfile:\n",
    "            txtfile.write(description)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#u can put any other location in raw string r\"<file path>\" and it will copy all the structure from cd to that fole path\n",
    "dump_data(sales_data, product_details, product_descriptions,os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
